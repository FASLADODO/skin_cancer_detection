{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile, io\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.preprocessing import image \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file):\n",
    "    base_url = 'https://s3-us-west-1.amazonaws.com/udacity-dlnfd/datasets/skin-cancer/'\n",
    "    r = requests.get(base_url + file, stream=True)\n",
    "    archive = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    \n",
    "    tensors = None\n",
    "    targets = []\n",
    "    for name in tqdm(archive.namelist()):\n",
    "        if name.endswith('.jpg'):\n",
    "            img = Image.open(io.BytesIO(archive.read(name))).resize((224,224))\n",
    "            x = image.img_to_array(img)\n",
    "            x = np.expand_dims(x, axis=0)\n",
    "            if tensors is None:\n",
    "                tensors = x\n",
    "            else:\n",
    "                tensors = np.vstack((tensors, x))\n",
    "            targets.append(name.split('/')[1])\n",
    "            \n",
    "    return tensors, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2004/2004 [17:43<00:00,  1.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 154/154 [00:51<00:00,  2.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 604/604 [06:56<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "train_tensors, train_targets = load_dataset('train.zip')\n",
    "valid_tensors, valid_targets = load_dataset('valid.zip')\n",
    "test_tensors, test_targets = load_dataset('test.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 224, 224, 3), (150, 224, 224, 3), (600, 224, 224, 3))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensors.shape, valid_tensors.shape, test_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import smtplib\n",
    "server = smtplib.SMTP( \"smtp.gmail.com\", 587 )\n",
    "server.starttls()\n",
    "server.login( 'nicholas.d.vasko@gmail.com', 'Fibonacci2' )\n",
    "server.sendmail( '', '7247141468@vtext.com', '%s\\n%s\\n%s' % (train_tensors.shape, valid_tensors.shape, test_tensors.shape) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_bottleneck_features import *\n",
    "\n",
    "def extract_bottleneck(tensors, extract_fn):\n",
    "    temp = None\n",
    "    for tensor in tqdm(tensors):\n",
    "        tensor = np.expand_dims(tensor, axis=0)\n",
    "        bottleneck_features = extract_fn(tensor)\n",
    "        if temp is None:\n",
    "            temp = bottleneck_features\n",
    "        else:\n",
    "            temp = np.vstack((temp, bottleneck_features))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensors = train_tensors[:2]\n",
    "valid_tensors = valid_tensors[:2]\n",
    "test_tensors = test_tensors[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG19 Bottleneck\n",
      "ResNet50 Bottleneck\n",
      "Inception Bottleneck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - ETA: 4: - ETA: 2: - ETA: 2: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 1: - ETA: 55s - ETA: 48 - ETA: 42 - ETA: 37 - ETA: 34 - ETA: 31 - ETA: 29 - ETA: 26 - ETA: 24 - ETA: 22 - ETA: 21 - ETA: 19 - ETA: 18 - ETA: 17 - ETA: 16 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 5s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [04:08<00:00, 124.36s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [04:28<00:00, 134.50s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [05:22<00:00, 161.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xception Bottleneck\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [04:39<00:00, 139.77s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [04:47<00:00, 143.85s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [05:04<00:00, 152.18s/it]\n"
     ]
    }
   ],
   "source": [
    "print('VGG19 Bottleneck')\n",
    "#train_VGG19 = extract_bottleneck(train_tensors, extract_VGG19)\n",
    "#valid_VGG19 = extract_bottleneck(valid_tensors, extract_VGG19)\n",
    "#test_VGG19 = extract_bottleneck(test_tensors, extract_VGG19)\n",
    "\n",
    "print('ResNet50 Bottleneck')\n",
    "#train_Resnet50 = extract_bottleneck(train_tensors, extract_Resnet50)\n",
    "#valid_Resnet50 = extract_bottleneck(valid_tensors, extract_Resnet50)\n",
    "#test_Resnet50 = extract_bottleneck(test_tensors, extract_Resnet50)\n",
    "\n",
    "print('InceptionV3 Bottleneck')\n",
    "train_Inception = extract_bottleneck(train_tensors, extract_InceptionV3)\n",
    "valid_Inception = extract_bottleneck(valid_tensors, extract_InceptionV3)\n",
    "test_Inception = extract_bottleneck(test_tensors, extract_InceptionV3)\n",
    "\n",
    "print('Xception Bottleneck')\n",
    "train_Xception = extract_bottleneck(train_tensors, extract_Xception)\n",
    "valid_Xception = extract_bottleneck(valid_tensors, extract_Xception)\n",
    "test_Xception = extract_bottleneck(test_tensors, extract_Xception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets_MM = [1 if x == 'malanoma' else 0 for x in train_targets]\n",
    "valid_targets_MM = [1 if x == 'malanoma' else 0 for x in valid_targets]\n",
    "test_targets_MM = [1 if x == 'malanoma' else 0 for x in test_targets]\n",
    "\n",
    "train_targets_SK = [0 if x == 'malanoma' else 1 for x in train_targets]\n",
    "valid_targets_SK = [0 if x == 'malanoma' else 1 for x in valid_targets]\n",
    "test_targets_SK = [0 if x == 'malanoma' else 1 for x in test_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicho\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG19_model_MM = Sequential()\n",
    "VGG19_model_MM.add(GlobalAveragePooling2D(input_shape=train_VGG19.shape[1:]))\n",
    "VGG19_model_MM.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "Resnet50_model_MM = Sequential()\n",
    "Resnet50_model_MM.add(GlobalAveragePooling2D(input_shape=train_Resnet50.shape[1:]))\n",
    "Resnet50_model_MM.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "Inception_model_MM = Sequential()\n",
    "Inception_model_MM.add(GlobalAveragePooling2D(input_shape=train_Inception.shape[1:]))\n",
    "Inception_model_MM.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "Xception_model_MM = Sequential()\n",
    "Xception_model_MM.add(GlobalAveragePooling2D(input_shape=train_Xception.shape[1:]))\n",
    "Xception_model_MM.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG19_model_SK = Sequential()\n",
    "VGG19_model_SK.add(GlobalAveragePooling2D(input_shape=train_VGG19.shape[1:]))\n",
    "VGG19_model_SK.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "Resnet50_model_SK = Sequential()\n",
    "Resnet50_model_SK.add(GlobalAveragePooling2D(input_shape=train_Resnet50.shape[1:]))\n",
    "Resnet50_model_SK.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "Inception_model_SK = Sequential()\n",
    "Inception_model_SK.add(GlobalAveragePooling2D(input_shape=train_Inception.shape[1:]))\n",
    "Inception_model_SK.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "Xception_model_SK = Sequential()\n",
    "Xception_model_SK.add(GlobalAveragePooling2D(input_shape=train_Xception.shape[1:]))\n",
    "Xception_model_SK.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "import tensorflow as tf\n",
    "\n",
    "def as_keras_metric(method):\n",
    "    import functools\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    @functools.wraps(method)\n",
    "    def wrapper(self, args, **kwargs):\n",
    "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
    "        value, update_op = method(self, args, **kwargs)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([update_op]):\n",
    "            value = tf.identity(value)\n",
    "        return value\n",
    "    return wrapper\n",
    "\n",
    "auc_roc = as_keras_metric(tf.metrics.auc)\n",
    "\n",
    "VGG19_model_MM.compile(loss='mean_squared_error', optimizer='adam', metrics=[auc_roc])\n",
    "#Resnet50_model_MM.compile(loss='mean_squared_error', optimizer='adam', metrics=[auc_roc])\n",
    "#Inception_model_MM.compile(loss='mean_squared_error', optimizer='adam', metrics=[auc_roc])\n",
    "#Xception_model_MM.compile(loss='mean_squared_error', optimizer='adam', metrics=[auc_roc])\n",
    "\n",
    "#VGG19_model_SK.compile(loss='mean_squared_error', optimizer='adam', metrics=[auc_roc])\n",
    "#Resnet50_model_SK.compile(loss='mean_squared_error', optimizer='adam', metrics=[auc_roc])\n",
    "#Inception_model_SK.compile(loss='mean_squared_error', optimizer='adam', metrics=[auc_roc])\n",
    "#Xception_model_SK.compile(loss='mean_squared_error', optimizer='adam', metrics=[auc_roc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "epochs = 20\n",
    "batch_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2 samples, validate on 2 samples\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 135s 67s/step - loss: 9.5501e-12 - auc: 0.0000e+00 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 9.5468e-12 - auc: 1.0000 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00181 to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 9.5422e-12 - auc: 1.0000 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00181 to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 9.5366e-12 - auc: 1.0000 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00181 to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 9.5300e-12 - auc: 1.0000 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00181 to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 9.5228e-12 - auc: 1.0000 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.00181 to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 9.5148e-12 - auc: 1.0000 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00181 to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 9.5062e-12 - auc: 1.0000 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.00181 to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 9.4971e-12 - auc: 1.0000 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.00181 to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 9.4874e-12 - auc: 1.0000 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.00181 to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 25ms/step - loss: 9.4771e-12 - auc: 1.0000 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.00181 to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 9.4665e-12 - auc: 1.0000 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.00181 to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 9.4554e-12 - auc: 1.0000 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00181 to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 9.4438e-12 - auc: 1.0000 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.00181 to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 9.4318e-12 - auc: 1.0000 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.00181 to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 9.4194e-12 - auc: 1.0000 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.00181 to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 23ms/step - loss: 9.4067e-12 - auc: 1.0000 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.00181 to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 21ms/step - loss: 9.3936e-12 - auc: 1.0000 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.00181 to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 9.3802e-12 - auc: 1.0000 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.00181 to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 24ms/step - loss: 9.3665e-12 - auc: 1.0000 - val_loss: 0.0018 - val_auc: 1.0000\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.00181 to 0.00181, saving model to saved_models/weights.best.VGG19_MM.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c2fad891d0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.VGG19_MM.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "VGG19_model_MM.fit(train_VGG19, train_targets_MM[:2], \n",
    "          validation_data=(valid_VGG19, valid_targets_MM[:2]),\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.Resnet50_MM.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "Resnet50_model_MM.fit(train_Resnet50, train_targets_MM, \n",
    "          validation_data=(valid_Resnet50, valid_targets_MM),\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.Inception_MM.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "Inception_model_MM.fit(train_Inception, train_targets_MM, \n",
    "          validation_data=(valid_Inception, valid_targets_MM),\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.Xception_MM.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "Xception_model_MM.fit(train_Xception, train_targets_MM, \n",
    "          validation_data=(valid_Xception, valid_targets_MM),\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.VGG19_SK.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "VGG19_model_SK.fit(train_VGG19, train_targets_SK, \n",
    "          validation_data=(valid_VGG19, valid_targets_SK),\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.Resnet50_SK.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "Resnet50_model_SK.fit(train_Resnet50, train_targets_SK, \n",
    "          validation_data=(valid_Resnet50, valid_targets_SK),\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.Inception_SK.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "Inception_model_SK.fit(train_Inception, train_targets_SK, \n",
    "          validation_data=(valid_Inception, valid_targets_SK),\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.Xception_SK.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "Xception_model_SK.fit(train_Xception, train_targets_SK, \n",
    "          validation_data=(valid_Xception, valid_targets_SK),\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'VGG19_model_MM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c5fcf54831cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mVGG19_model_MM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'saved_models/weights.best.VGG19_MM.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#Resnet50_model_MM.load_weights('saved_models/weights.best.Resnet50_MM.hdf5')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Inception_model_MM.load_weights('saved_models/weights.best.Inception_MM.hdf5')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Xception_model_MM.load_weights('saved_models/weights.best.Xception_MM.hdf5')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'VGG19_model_MM' is not defined"
     ]
    }
   ],
   "source": [
    "VGG19_model_MM.load_weights('saved_models/weights.best.VGG19_MM.hdf5')\n",
    "#Resnet50_model_MM.load_weights('saved_models/weights.best.Resnet50_MM.hdf5')\n",
    "#Inception_model_MM.load_weights('saved_models/weights.best.Inception_MM.hdf5')\n",
    "#Xception_model_MM.load_weights('saved_models/weights.best.Xception_MM.hdf5')\n",
    "\n",
    "#VGG19_model_SK.load_weights('saved_models/weights.best.VGG19_SK.hdf5')\n",
    "#Resnet50_model_SK.load_weights('saved_models/weights.best.Resnet50_SK.hdf5')\n",
    "#Inception_model_SK.load_weights('saved_models/weights.best.Inception_SK.hdf5')\n",
    "#Xception_model_SK.load_weights('saved_models/weights.best.Xception_SK.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get index of prediction for each image in test set\n",
    "VGG19_predictions_MM = [np.argmax(VGG19_model_MM.predict(np.expand_dims(feature, axis=0))) for feature in test_VGG19]\n",
    "Resnet50_predictions_MM = [np.argmax(Resnet50_model_MM.predict(np.expand_dims(feature, axis=0))) for feature in test_Resnet50]\n",
    "Inception_predictions_MM = [np.argmax(Inception_model_MM.predict(np.expand_dims(feature, axis=0))) for feature in test_Inception]\n",
    "Xception_predictions_MM = [np.argmax(Xception_model_MM.predict(np.expand_dims(feature, axis=0))) for feature in test_Xception]\n",
    "\n",
    "# report test accuracy\n",
    "VGG19_test_accuracy_MM = 100*np.sum(np.array(VGG19_predictions_MM)==np.argmax(test_targets_MM, axis=1))/len(VGG19_predictions_MM)\n",
    "Resnet50_test_accuracy_MM = 100*np.sum(np.array(Resnet50_predictions_MM)==np.argmax(test_targets_MM, axis=1))/len(Resnet50_predictions_MM)\n",
    "Inception_test_accuracy_MM = 100*np.sum(np.array(Inception_predictions_MM)==np.argmax(test_targets_MM, axis=1))/len(Inception_predictions_MM)\n",
    "Xception_test_accuracy_MM = 100*np.sum(np.array(Xception_predictions_MM)==np.argmax(test_targets_MM, axis=1))/len(Xception_predictions_MM)\n",
    "\n",
    "# get index of prediction for each image in test set\n",
    "VGG19_predictions_SK = [np.argmax(VGG19_model_SK.predict(np.expand_dims(feature, axis=0))) for feature in test_VGG19]\n",
    "Resnet50_predictions_SK = [np.argmax(Resnet50_model_SK.predict(np.expand_dims(feature, axis=0))) for feature in test_Resnet50]\n",
    "Inception_predictions_SK = [np.argmax(Inception_model_SK.predict(np.expand_dims(feature, axis=0))) for feature in test_Inception]\n",
    "Xception_predictions_SK = [np.argmax(Xception_model_SK.predict(np.expand_dims(feature, axis=0))) for feature in test_Xception]\n",
    "\n",
    "# report test accuracy\n",
    "VGG19_test_accuracy_SK = 100*np.sum(np.array(VGG19_predictions_SK)==np.argmax(test_targets_SK, axis=1))/len(VGG19_predictions_SK)\n",
    "Resnet50_test_accuracy_SK = 100*np.sum(np.array(Resnet50_predictions_SK)==np.argmax(test_targets_SK, axis=1))/len(Resnet50_predictions_SK)\n",
    "Inception_test_accuracy_SK = 100*np.sum(np.array(Inception_predictions_SK)==np.argmax(test_targets_SK, axis=1))/len(Inception_predictions_SK)\n",
    "Xception_test_accuracy_SK = 100*np.sum(np.array(Xception_predictions_SK)==np.argmax(test_targets_SK, axis=1))/len(Xception_predictions_SK)\n",
    "\n",
    "print('Melonoma detection')\n",
    "print('-----------------------------')\n",
    "print('VGG19 test accuracy: %.4f%%' % VGG19_test_accuracy_MM)\n",
    "print('Resnet50 test accuracy: %.4f%%' % Resnet50_test_accuracy_MM)\n",
    "print('Inception test accuracy: %.4f%%' % Inception_test_accuracy_MM)\n",
    "print('Xception test accuracy: %.4f%%' % Xception_test_accuracy_MM)\n",
    "\n",
    "print('Melanocytic detection')\n",
    "print('-----------------------------')\n",
    "print('VGG19 test accuracy: %.4f%%' % VGG19_test_accuracy_SK)\n",
    "print('Resnet50 test accuracy: %.4f%%' % Resnet50_test_accuracy_SK)\n",
    "print('Inception test accuracy: %.4f%%' % Inception_test_accuracy_SK)\n",
    "print('Xception test accuracy: %.4f%%' % Xception_test_accuracy_SK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predictions_MM = \n",
    "best_predictions_SK = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/test'\n",
    "filenames =  glob(path + '/melanoma/*')\n",
    "filenames.extend(glob(path + '/nevus/*'))\n",
    "filenames.extend(glob(path + '/seborrheic_keratosis/*'))\n",
    "\n",
    "output = pd.DataFrame()\n",
    "output['Id'] = filenames\n",
    "output['task_1'] = best_predictions_MM\n",
    "output['task_2'] = best_predictions_SK\n",
    "\n",
    "output.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
